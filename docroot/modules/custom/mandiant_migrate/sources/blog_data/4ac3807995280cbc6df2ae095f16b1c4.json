{
  "jcr:primaryType": "cq:Page",
  "jcr:createdBy": "admin",
  "jcr:created": "Tue Mar 12 2019 11:04:03 GMT-0400",
  "jcr:content": {
    "jcr:primaryType": "cq:PageContent",
    "jcr:mixinTypes": [
      "mix:versionable"
    ],
    "jcr:createdBy": "admin",
    "jcr:title": "Going ATOMIC: Clustering and Associating Attacker Activity at Scale",
    "cq:lastReplicationAction": "Activate",
    "jcr:versionHistory": "e22f71ce-18a5-4c0c-a09b-99cf4ba3eb9b",
    "author": "Matt Berninger",
    "cq:template": "\/apps\/fireeye-blog\/templates\/page_blogpost",
    "cq:lastReplicatedBy": "adam.greenberg@fireeye.com",
    "jcr:language": "en_us",
    "jcr:predecessors": [
      "8ed67433-30a8-4fc6-900c-3b89033752c7"
    ],
    "jcr:created": "Tue Mar 12 2019 11:04:03 GMT-0400",
    "cq:lastReplicated": "Tue Mar 12 2019 11:04:01 GMT-0400",
    "cq:lastModified": "Tue Mar 12 2019 11:03:08 GMT-0400",
    "jcr:baseVersion": "8ed67433-30a8-4fc6-900c-3b89033752c7",
    "jcr:isCheckedOut": true,
    "cq:tags": [
      "fireeye-blog-authors:matt-berninger",
      "fireeye-blog-threat-research:threat-research",
      "fireeye-blog-tags:homepage-carousel",
      "fireeye-blog-tags:latest",
      "fireeye-blog-tags:data",
      "fireeye-blog-tags:machine-learning",
      "fireeye-blog-tags:analysis"
    ],
    "jcr:uuid": "9d61e6cd-95a8-473f-8055-8afe467df5ae",
    "sling:resourceType": "social\/blog\/components\/page",
    "published": "Tue Mar 12 2019 11:00:00 GMT-0400",
    "cq:lastModifiedBy": "adam.greenberg@fireeye.com",
    "par": {
      "jcr:primaryType": "nt:unstructured",
      "sling:resourceType": "foundation\/components\/parsys",
      "entry": {
        "jcr:primaryType": "nt:unstructured",
        "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
        "text": "\u003Cp\u003EAt FireEye, we work hard to detect, track, and stop attackers. As part of this work, we learn a great deal of information about how various attackers operate, including details about commonly used malware, infrastructure, delivery mechanisms, and other tools and techniques. This knowledge is built up over hundreds of investigations and thousands of hours of analysis each year. At the time of publication, we have 50 APT or FIN groups, each of which have distinct characteristics. We have also collected thousands of uncharacterized \u0027clusters\u0027 of related activity about which we have not yet made any formal attribution claims. While unattributed, these clusters are still useful in the sense that they allow us to group and track associated activity over time.\u003C\/p\u003E\n\u003Cp\u003EHowever, as the information we collect grows larger and larger, we realized we needed an algorithmic method to assist in analyzing this information at scale, to discover new potential overlaps and attributions. This blog post will outline the data we used to build the model, the algorithm we developed, and some of the challenges we hope to tackle in the future.\u003C\/p\u003E\n\u003Ch4\u003EThe Data\u003C\/h4\u003E\n\u003Cp\u003EAs we detect and uncover malicious activity, we group forensically-related artifacts into \u0027clusters\u0027. These clusters indicate actions, infrastructure, and malware that are all part of an intrusion, campaign, or series of activities which have direct links. These are what we call our \u0026quot;UNC\u0026quot; or \u0026quot;uncategorized\u0026quot; groups. Over time, these clusters can grow, merge with other clusters, and potentially \u0027graduate\u0027 into named groups, such as APT33 or FIN7. This graduation occurs only when we understand enough about their operations in each phase of the attack lifecycle and have associated the activity with a state-aligned program or criminal operation.\u003C\/p\u003E\n\u003Cp\u003EFor every group, we can generate a summary document that contains information broken out into sections such as infrastructure, malware files, communication methods, and other aspects. Figure 1 shows a fabricated example with the various \u0027topics\u0027 broken out. Within each \u0027topic\u0027\u0026nbsp;\u2013 such as \u0027Malware\u0027\u0026nbsp;\u2013 we have various \u0027terms\u0027, which have associated counts. These numbers indicate how often we have recorded a group using that \u0027term\u0027.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture1.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 1: Example group \u0027documents\u0027 demonstrating how data about groups is recorded\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch4\u003EThe Problem\u003C\/h4\u003E\n\u003Cp\u003EOur end goal is always to merge a new group either into an existing group once the link can be proven, or to graduate it to its own group if we are confident it represents a new and distinct actor set. These clustering and attribution decisions have thus far been performed manually and require rigorous analysis and justification. However, as we collect increasingly more data about attacker activities, this manual analysis becomes a bottleneck. Clusters risk going unanalyzed, and potential associations and attributions could slip through the cracks. Thus, we now incorporate a machine learning-based model into our intelligence analysis to assist with discovery, analysis, and justification for these claims.\u003C\/p\u003E\n\u003Cp\u003EThe model we developed began with the following goals:\u003C\/p\u003E\n\u003Col style=\u0022list-style-position: inside;\u0022\u003E\n\u003Cli\u003ECreate a single, interpretable similarity metric between groups\u003C\/li\u003E\n\u003Cli\u003EEvaluate past analytical decisions\u003C\/li\u003E\n\u003Cli\u003EDiscover new potential matches\u003C\/li\u003E\n\u003C\/ol\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture2.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 2: Example documents highlighting observed term overlaps between two groups\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch4\u003EThe Model\u003C\/h4\u003E\n\u003Cp\u003EThis model uses a document clustering approach, familiar in the data science realm and often explained in the context of grouping books or movies. Applying the approach to our structured documents about each group, we can evaluate similarities between groups at scale.\u003C\/p\u003E\n\u003Cp\u003EFirst, we decided to model each topic individually. This decision means that each topic will result in its own measure of similarity between groups, which will ultimately be aggregated to produce a holistic similarity measure.\u003C\/p\u003E\n\u003Cp\u003EHere is how we apply this to our documents.\u003C\/p\u003E\n\u003Cp\u003EWithin each topic, every distinct term is transformed into a value using a method called term frequency -inverse document frequency, or \u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/en.wikipedia.org\/wiki\/Tf%E2%80%93idf\u0022\u003ETF-IDF\u003C\/a\u003E. This transformation is applied to every unique term for every document + topic, and the basic intuition behind it is to:\u003C\/p\u003E\n\u003Col style=\u0022list-style-position: inside;\u0022\u003E\n\u003Cli\u003EIncrease importance of the term if it occurs often with the document.\u003C\/li\u003E\n\u003Cli\u003EDecrease the importance of the term if it appears commonly across all documents.\u003C\/li\u003E\n\u003C\/ol\u003E\n\u003Cp\u003EThis approach rewards distinctive terms such as custom malware families\u0026nbsp;\u2013 which may appear for only a handful of groups \u2013 and down-weights common things such as \u0027spear-phishing\u0027, which appear for the vast majority of groups.\u003C\/p\u003E\n\u003Cp\u003EFigure 3 shows an example of TF-IDF being applied to a fictional \u0026quot;UNC599\u0026quot; for two terms:\u0026nbsp;\u003Ci\u003Emal.sogu\u003C\/i\u003E and \u003Ci\u003Emal.threebyte\u003C\/i\u003E. These terms indicate the usages of SOGU and THREEBYTE within the \u0027malware\u0027 topic and thus we calculate their value within that topic using TF-IDF. The first (TF) value is how often those terms appeared as a fraction of all malware terms for the group. The second value (IDF) is the inverse of how frequently those terms appear across all groups. Additionally, we take the natural log of the IDF value, to smooth the effects of highly common terms \u2013 as you can see in the graph, when the value is close to 1 (very common terms), the log evaluates to near-zero, thus down-weighting the final TF x IDF value. Unique values have a much higher IDF, and thus result in higher values.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture3.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 3: Breakdown of TF-IDF metric when evaluated for a single group in regard to malware\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EOnce each term has been given a score, each group is now reflected as a collection of distinct topics, and each topic is a vector of scores for the terms it contains. Each vector can be conceived as an arrow, detailing the \u0027direction\u0027 that group is \u0027pointing\u0027within that topic.\u003C\/p\u003E\n\u003Cp\u003EWithin each topic space, we can then evaluate the similarity of various groups using another method \u2013 \u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/en.wikipedia.org\/wiki\/Cosine_similarity\u0022\u003ECosine Similarity\u003C\/a\u003E. If, like me, you did not love trigonometry \u2013 fear not! The intuition is simple. In essence, this is a measure of how \u003Ci\u003Eparallel\u003C\/i\u003E two vectors are. As seen in Figure 4, to evaluate two groups\u0027 usage of malware, we plot their malware vectors and see if they are pointing in the same direction. More parallel means they are more similar.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture4.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 4: Simplified breakdown of Cosine Similarity metric when applied to two groups in the malware \u0027space\u0027\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EOne of the nice things about this approach is that large and small vectors are treated the same \u2013 thus, a new, relatively small UNC cluster pointing in the same direction as a well-documented APT group will still reflect a high level of similarity. This is one of the primary use cases we have, discovering new clusters of activity with high similarity to already established groups.\u003C\/p\u003E\n\u003Cp\u003EUsing TF-IDF and Cosine Similarity, we can now calculate the topic-specific similarities for every group in our corpus of documents. The final step is to combine these topic similarities into a single, aggregate metric (Figure 5). This single metric allows us to quickly query our data for \u0027groups similar to X\u0027 or \u0027similarity between X and Y\u0027. The question then becomes: What is the best way to build this final similarity?\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture5.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 5: Overall model flow diagram showing individual topic similarities and aggregation in to final similarity matrix\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EThe simplest approach is to take an average, and at first that\u2019s exactly what we did. However, as analysts, this approach did not sync well with analyst intuition. As analysts, we feel that some topics matter more than others. Malware and methodologies \u003Ci\u003Eshould \u003C\/i\u003Ebe more important than say, server locations or target industries...right? However, when challenged to provide custom weightings for each topic, it was impossible to find an objective weighting system, free from analyst bias. Finally, we thought: \u0026quot;What if we used existing, known data to \u003Ci\u003Etell \u003C\/i\u003Eus what the right weights are?\u0026quot; In order to do that, we needed a lot of known \u2013 or \u0026quot;labeled\u0026quot;\u0026nbsp;\u2013 examples of both similar and dissimilar groups.\u003C\/p\u003E\n\u003Ch4\u003EBuilding a Labeled Dataset\u003C\/h4\u003E\n\u003Cp\u003EAt first our concept seemed straightforward: We would find a large dataset of labeled pairs, and then fit a regression model to accurately classify them. If successful, this model should give us the weights we wanted to discover.\u003C\/p\u003E\n\u003Cp\u003EFigure 6 shows some graphical intuition behind this approach. First, using a set of \u2018labeled\u2019 pairs, we fit a function which best predicts the data points.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture6.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 6: Example Linear regression plot \u2013 in reality we used a Logistic Regression, but showing a linear model to demonstrate the intuition\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EThen, we use that same function to predict the aggregate similarity of un-labeled pairs (Figure 7).\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture7b.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 7: Example of how we used the trained model to predict final similarity from individual topic similarities.\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EHowever, our data posed a unique problem in the sense that only a tiny fraction of \u003Ci\u003Eall \u003C\/i\u003Epotential pairings had ever been analyzed. These analyses happened manually and sporadically, often the result of sudden new information from an investigation finally linking two groups together. As a labeled dataset, these pairs were woefully insufficient for any rigorous evaluation of the approach. We needed more labeled data.\u003C\/p\u003E\n\u003Cp\u003ETwo of our data scientists suggested a clever approach: What if we created thousands of \u0027fake\u0027 clusters by randomly sampling from well-established APT groups? We could therefore label any two samples that came from the same group as definitely similar, and any two from separate groups as not similar (Figure 8). This gave us the ability to synthetically generate the labeled dataset we desperately needed. Then, using a linear regression model, we were able to elegantly solve this \u0027weighted average\u0027 problem rather than depend on subjective guesses.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/atomicity\/Picture8.png\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 8: Example similarity testing with \u0027fake\u0027 clusters derived from known APT groups\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EAdditionally, these synthetically created clusters gave us a dataset upon which to test various iterations of the model. What if we remove a topic? What if we change the way we capture terms? Using a large labeled dataset, we can now benchmark and evaluate performance as we update and improve the model.\u003C\/p\u003E\n\u003Cp\u003ETo evaluate the model, we observe several metrics:\u003C\/p\u003E\n\u003Cul style=\u0022list-style-position: inside;\u0022\u003E\n\u003Cli\u003ERecall for synthetic clusters we know come from the same original group \u2013 how many do we get right\/wrong? This evaluates the accuracy of a given approach.\u003C\/li\u003E\n\u003Cli\u003EFor individual topics, the \u0027spread\u0027 between the calculated similarity of related and unrelated clusters. This helps us identify which topics help separate the classes best.\u003C\/li\u003E\n\u003Cli\u003EThe accuracy of a trained regression model, as a proxy for the \u0027signal\u0027 between similar and dissimilar clusters, as represented by the topics. This can help us identify overfitting issues as well.\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003Ch4\u003EOperational Use\u003C\/h4\u003E\n\u003Cp\u003EIn our daily operations, this model serves to augment and assist our intelligence experts. Presenting objective similarities, it can challenge biases and introduce new lines of investigation not previously considered. When dealing with thousands of clusters and new ones added every day from analysts around the globe, even the most seasoned and aware intel analyst could be excused for missing a potential lead. However, our model is able to present probable merges and similarities to analysts on demand, and thus can assist them in discovery.\u003C\/p\u003E\n\u003Cp\u003EUpon deploying this to our systems in December 2018, we immediately found benefits. One example is outlined in this \u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/www.fireeye.com\/blog\/threat-research\/2018\/12\/overruled-containing-a-potentially-destructive-adversary.html\u0022\u003Eblog post about potentially destructive attacks\u003C\/a\u003E. Since then we have been able to inform, discover, or justify dozens of other merges.\u003C\/p\u003E\n\u003Ch4\u003EFuture Work\u003C\/h4\u003E\n\u003Cp\u003ELike all models, this one has its weaknesses and we are already working on improvements. There is label noise in the way we manually enter information from investigations. There is sometimes \u0027extraneous\u0027 data about attackers that is not (yet) represented in our documents. Most of all, we have not yet fully incorporated the \u0027time of activity\u0027 and instead rely on \u0027time of recording\u0027. This introduces a lag in our representation, which makes time-based analysis difficult. What an attacker has done \u003Ci\u003Elately\u003C\/i\u003E should likely mean more than what they did five years ago.\u003C\/p\u003E\n\u003Cp\u003ETaking this objective approach and building the model has not only improved our intel operations, but also highlighted data requirements for future modeling efforts. As we have seen in other domains, building a machine learning model on top of forensic data can quickly highlight potential improvements to data modeling, storage, and access.\u0026nbsp;Further information on this model can also be viewed in this \u003Ca href=\u0022https:\/\/www.youtube.com\/watch?v=zMdHGY53VEw\u0022\u003Evideo\u003C\/a\u003E, from a presentation at the 2018 \u003Ca href=\u0022https:\/\/www.camlis.org\/\u0022\u003ECAMLIS\u003C\/a\u003E conference.\u003C\/p\u003E\n\u003Cp\u003EWe have thus far enjoyed taking this approach to augmenting our intelligence model and are excited about the potential paths forward. Most of all, we look forward to the modeling efforts that help us profile, attribute, and stop attackers.\u003C\/p\u003E\n",
        "jcr:lastModified": "Tue Mar 12 2019 11:02:46 GMT-0400",
        "sling:resourceType": "social\/blog\/components\/entrytext"
      }
    },
    "summary": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "text": "\u003Cp\u003EAn algorithmic method to assist in analyzing information at scale.\u003C\/p\u003E\n",
      "jcr:lastModified": "Mon Mar 11 2019 19:10:00 GMT-0400",
      "sling:resourceType": "social\/blog\/components\/entrytextteaser"
    },
    "image": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "jcr:lastModified": "Tue Mar 12 2019 11:03:08 GMT-0400",
      "imageRotate": "0"
    }
  }
}
