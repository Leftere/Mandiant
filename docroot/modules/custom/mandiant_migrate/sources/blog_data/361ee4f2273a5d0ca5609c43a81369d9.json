{
  "jcr:primaryType": "cq:Page",
  "jcr:createdBy": "fireeye_global_admin",
  "jcr:created": "Thu Nov 14 2019 17:00:24 GMT+0000",
  "jcr:content": {
    "jcr:primaryType": "cq:PageContent",
    "jcr:mixinTypes": [
      "mix:versionable"
    ],
    "jcr:createdBy": "fireeye_global_admin",
    "jcr:title": "Attention is All They Need: Combatting Social Media Information Operations With Neural Language Models",
    "jcr:versionHistory": "974d4a7e-0b75-407c-9e12-4e21715ed48b",
    "author": "Sajidur Rahman",
    "cq:template": "\/apps\/fireeye-blog\/templates\/page_blogpost",
    "jcr:language": "en_us",
    "jcr:predecessors": [
      "b546b148-a808-4100-82dd-1a035cd83dc7"
    ],
    "jcr:created": "Thu Nov 14 2019 17:07:43 GMT+0000",
    "cq:lastModified": "Thu Nov 14 2019 17:07:33 GMT+0000",
    "jcr:baseVersion": "b546b148-a808-4100-82dd-1a035cd83dc7",
    "jcr:isCheckedOut": true,
    "cq:tags": [
      "fireeye-blog-authors:sajidur-rahman",
      "fireeye-blog-authors:philip-tully",
      "fireeye-blog-authors:lee-foster",
      "fireeye-blog-threat-research:threat-research",
      "fireeye-blog-tags:data-science",
      "fireeye-blog-tags:latest",
      "fireeye-blog-tags:machine-learning",
      "fireeye-blog-tags:homepage-carousel",
      "fireeye-blog-tags:intelligence",
      "fireeye-blog-tags:social-media"
    ],
    "jcr:uuid": "de707597-18f9-46cb-9cb0-8bd4b0983390",
    "sling:resourceType": "social\/blog\/components\/page",
    "published": "Thu Nov 14 2019 12:00:00 GMT-0500",
    "cq:lastModifiedBy": "adam.greenberg@fireeye.com",
    "par": {
      "jcr:primaryType": "nt:unstructured",
      "sling:resourceType": "foundation\/components\/parsys",
      "entry": {
        "jcr:primaryType": "nt:unstructured",
        "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
        "text": "\u003Cp\u003EInformation operations have flourished on social media in part because they can be conducted cheaply, are relatively low risk, have immediate global reach, and can exploit the type of viral amplification incentivized by platforms. Using networks of coordinated accounts, social media-driven information operations disseminate and amplify content designed to promote specific political narratives, manipulate public opinion, foment discord, or achieve strategic ideological or geopolitical objectives. FireEye\u2019s recent public reporting illustrates the continually evolving use of social media as a vehicle for this activity, highlighting information operations supporting Iranian political interests such as one that \u003Ca href=\u0022https:\/\/www.fireeye.com\/blog\/threat-research\/2018\/08\/suspected-iranian-influence-operation.html\u0022\u003Eleveraged a network of inauthentic news sites and social media accounts\u003C\/a\u003E and another that \u003Ca href=\u0022https:\/\/www.fireeye.com\/blog\/threat-research\/2019\/05\/social-media-network-impersonates-us-political-candidates-supports-iranian-interests.html\u0022\u003Eimpersonated real individuals and leveraged legitimate news outlets\u003C\/a\u003E.\u003C\/p\u003E\n\u003Cp\u003EIdentifying sophisticated activity of this nature often requires the subject matter expertise of human analysts. After all, such content is purposefully and convincingly manufactured to imitate authentic online activity, making it difficult for casual observers to properly verify. The actors behind such operations are not transparent about their affiliations, often undertaking concerted efforts to mask their origins through elaborate false personas and the adoption of other operational security measures. With these operations being intentionally designed to deceive humans, can we turn towards automation to help us understand and detect this growing threat? Can we make it easier for analysts to discover and investigate this activity despite the heterogeneity, high traffic, and sheer scale of social media?\u003C\/p\u003E\n\u003Cp\u003EIn this blog post, we will illustrate an example of how the FireEye Data Science (FDS) team works together with FireEye\u2019s Information Operations Analysis team to better understand and detect social media information operations using neural language models.\u003C\/p\u003E\n\u003Ctable border=\u00221\u0022 cellspacing=\u00220\u0022 cellpadding=\u00220\u0022 width=\u0022624\u0022\u003E\n\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd width=\u0022624\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\u003Cu\u003EHighlights\u003C\/u\u003E\u003C\/p\u003E\n\u003Cul\u003E\n\u003Cli\u003EA new breed of deep neural networks uses an attention mechanism to home in on patterns within text, allowing us to better analyze the linguistic fingerprints and semantic stylings of information operations using modern Transformer models.\u003C\/li\u003E\n\u003Cli\u003EBy fine-tuning an open source Transformer known as GPT-2, we can detect social media posts being leveraged in information operations despite their syntactic differences to the model\u2019s original training data.\u003C\/li\u003E\n\u003Cli\u003ETransfer learning from pre-trained neural language models lowers the barrier to entry for generating high-quality synthetic text at scale, and this has implications for the future of both red and blue team operations as such models become increasingly commoditized.\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003C\/tbody\u003E\u003C\/table\u003E\n\u003Ch4\u003EBackground: Using GPT-2 for Transfer Learning\u003C\/h4\u003E\n\u003Cp\u003E\u003Ca href=\u0022https:\/\/openai.com\/blog\/better-language-models\/\u0022\u003EOpenAI\u2019s updated Generative Pre-trained Transformer (GPT-2)\u003C\/a\u003E is an open source deep neural network that was trained in an unsupervised manner on the causal \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Language_model\u0022\u003Elanguage modeling task\u003C\/a\u003E. The objective of this language modeling task is to predict the next word in a sentence from previous context, meaning that a trained model ends up being capable of language generation. If the model can predict the next word accurately, it can be used in turn to predict the following word, and then so on and so forth until eventually, the model produces fully coherent sentences and paragraphs. Figure 1 depicts an example of language model (LM) predictions we generated using GPT-2. To generate text, \u003Ca href=\u0022https:\/\/arxiv.org\/abs\/1904.09751\u0022\u003Esingle words are successively sampled from distributions of candidate words\u003C\/a\u003E predicted by the model until it predicts an \u003Cspan class=\u0022code\u0022\u003E\u0026lt;|endoftext|\u0026gt;\u003C\/span\u003E word, which signals the end of the generation.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/dsio\/fig1.png\u0022 alt=\u0022\u0022\u003E\u003Cspan class=\u0022type-XS\u0022\u003E\u003Cbr\u003E\nFigure 1: An example GPT-2 generation prior to fine-tuning after priming the model with the phrase \u201cIt\u2019s disgraceful that.\u201d\u0026nbsp;\u0026nbsp;\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EThe quality of this synthetically generated text along with GPT-2\u2019s state of the art accuracy on a host of other natural language processing (NLP) benchmark tasks is due in large part to the model\u2019s improvements over prior 1) neural network architectures and 2) approaches to representing text. GPT-2 uses an attention mechanism to selectively focus the model on relevant pieces of text sequences and identify relationships between positionally distant words. In terms of architectures, Transformers use attention to decrease the time required to train on enormous datasets; they also tend to model lengthy text and scale better than other competing \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network\u0022\u003Efeedforward\u003C\/a\u003E and \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory\u0022\u003Erecurrent\u003C\/a\u003E neural networks. In terms of representing text, \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Word2vec\u0022\u003Eword embeddings\u003C\/a\u003E were a popular way to initialize just the first layer of neural networks, but such shallow representations required being trained from scratch for each new NLP task and in order to deal with new vocabulary. GPT-2 instead pre-trains \u003Ci\u003Eall\u003C\/i\u003E the model\u2019s layers using \u003Ca href=\u0022https:\/\/arxiv.org\/abs\/1801.06146\u0022\u003Ehierarchical representations\u003C\/a\u003E, which better capture language semantics and are readily transferable to other NLP tasks and new vocabulary.\u003C\/p\u003E\n\u003Cp\u003EThis \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Transfer_learning\u0022\u003Etransfer learning\u003C\/a\u003E method is advantageous because it allows us to avoid starting from scratch for each and every new NLP task. In transfer learning, we start from a large generic model that has been pre-trained for an initial task where copious data is available. We then leverage the model\u2019s acquired knowledge to train it further on a different, smaller dataset so that it excels at a subsequent, related task. This process of training the model further is referred to as fine-tuning, which involves re-learning portions of the model by adjusting its underlying parameters. Fine-tuning not only requires less data compared to training from scratch, but typically also requires less compute time and resources.\u003C\/p\u003E\n\u003Cp\u003EIn this blog post, we will show how to perform transfer learning from a pre-trained GPT-2 model in order to better understand and detect information operations on social media. Transformers have shown that \u003Ca href=\u0022https:\/\/arxiv.org\/abs\/1706.03762\u0022\u003EAttention is All You Need\u003C\/a\u003E, but here we will also show that Attention is All \u003Ci\u003EThey \u003C\/i\u003ENeed: while transfer learning may allow us to more easily detect information operations activity, it likewise lowers the barrier to entry for actors seeking to engage in this activity at scale.\u003C\/p\u003E\n\u003Ch4\u003EUnderstanding Information Operations Activity Using Fine-Tuned Neural Generations\u003C\/h4\u003E\n\u003Cp\u003EIn order to study the thematic and linguistic characteristics of a common type of social media-driven information operations activity, we first fine-tuned an LM that could perform text generation. Since the pre-trained GPT-2 model\u0027s dataset consisted of 40+ GB of Internet text data extracted from 8+ million reputable web pages, its generations display relatively formal grammar, punctuation, and structure that corresponds to the text present within that original dataset (e.g. Figure 1). To make it appear like social media posts with their shorter length, informal grammar, erratic punctuation, and syntactic quirks including @mentions, #hashtags, emojis, acronyms, and abbreviations, we fine-tuned the pre-trained GPT-2 model on a new language modeling task using additional training data.\u003C\/p\u003E\n\u003Cp\u003EFor the set of experiments presented in this blog post, this additional training data was obtained from the following open source datasets of identified accounts operated by Russia\u2019s famed Internet Research Agency (IRA) \u201ctroll factory\u201d:\u003C\/p\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ca href=\u0022https:\/\/www.nbcnews.com\/tech\/social-media\/now-available-more-200-000-deleted-russian-troll-tweets-n844731\u0022\u003ENBCNews\u003C\/a\u003E, over 200,000 tweets posted between 2014 and 2017 tied to IRA \u201cmalicious activity.\u201d\u003C\/li\u003E\n\u003Cli\u003E\u003Ca href=\u0022https:\/\/fivethirtyeight.com\/features\/why-were-sharing-3-million-russian-troll-tweets\/\u0022\u003EFiveThirtyEight\u003C\/a\u003E, over 1.8 million tweets associated with IRA activity between 2012 and 2018; we used accounts categorized as Left Troll, Right Troll, or Fearmonger.\u003C\/li\u003E\n\u003Cli\u003E\u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/about.twitter.com\/en_us\/values\/elections-integrity.html#data\u0022\u003ETwitter Elections Integrity\u003C\/a\u003E, almost 3 million tweets that were part of the influence effort by the IRA around the 2016 U.S. presidential election.\u003C\/li\u003E\n\u003Cli\u003E\u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/github.com\/ALCC01\/reddit-suspicious-accounts\u0022\u003EReddit Suspicious Accounts\u003C\/a\u003E, consisting of comments and submissions emanating from 944 accounts of suspected IRA origin.\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003Cp\u003EAfter combining these four datasets, we sampled English-language social media posts from them to use as input for our fine-tuned LM. Fine-tuning experiments were carried out in PyTorch using the 355 million parameter pre-trained GPT-2 model from \u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/github.com\/huggingface\/transformers\u0022\u003EHuggingFace\u2019s \u003Cspan class=\u0022code\u0022\u003Etransformers\u003C\/span\u003E library\u003C\/a\u003E, and were distributed over up to 8 GPUs.\u003C\/p\u003E\n\u003Cp\u003EAs opposed to other pre-trained LMs, \u003Ca href=\u0022https:\/\/openai.com\/blog\/language-unsupervised\/\u0022\u003EGPT-2 conveniently requires minimal architectural changes and parameter updates in order to be fine-tuned on new downstream tasks\u003C\/a\u003E. We simply processed social media posts from the above datasets through the pre-trained model, whose activations were then fed through adjustable weights into a linear output layer. The fine-tuning objective here was the same that GPT-2 was originally trained on (i.e. the language modeling task of predicting the next word, see Figure 1), except now its training dataset included text from social media posts. We also added the \u003Cspan class=\u0022code\u0022\u003E\u0026lt;|endoftext|\u0026gt;\u003C\/span\u003E string as a suffix to each post to adapt the model to the shorter length of social media text, meaning posts were fed into the model according to:\u003C\/p\u003E\n\u003Cp style=\u0022text-align: center;\u0022\u003E\u003Cspan class=\u0022code\u0022\u003E\u201c#Fukushima2015 Zaporozhia NPP can explode at any time\u003Cbr\u003E\n and that\u0027s awful! OMG! No way! #Nukraine\u0026lt;|endoftext|\u0026gt;\u201d\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EFigure 2 depicts a few example generations made after fine-tuning GPT-2 on the IRA datasets. Observe how these text generations are formatted like something we might expect to encounter scrolling through social media \u2013 they are short yet biting, express certainty and outrage regarding political issues, and contain emphases like an exclamation point. They also contain idiosyncrasies like hashtags and emojis that positionally manifest at the end of the generated text, depicting a semantic style regularly exhibited by actual users.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/dsio\/fig2.png\u0022 alt=\u0022\u0022\u003E\u003Cspan class=\u0022type-XS\u0022\u003E\u003Cbr\u003E\nFigure 2: Fine-tuning GPT-2 using the IRA datasets for the language modeling task. Example generations are primed with the same phrase from Figure 1, \u201cIt\u2019s disgraceful that.\u201d Hyphens are added for readability and not produced by the model.\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EHow does the model produce such credible generations? Besides the weights that were adjusted during LM fine-tuning, some of the heavy lifting is also done by the underlying attention scores that were learned by GPT-2\u2019s Transformer. Attention scores are computed between all words in a text sequence, and represent how important one word is when determining how important its nearby words will be in the next learning iteration. To compute attention scores, the Transformer \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Dot_product\u0022\u003Eperforms a dot product\u003C\/a\u003E between a Query vector\u003Ci\u003E q\u003C\/i\u003E and a Key vector \u003Ci\u003Ek\u003C\/i\u003E:\u003C\/p\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ci\u003Eq \u003C\/i\u003Eencodes the current hidden state, representing the word that searches for other words in the sequence to pay attention to that may help supply context for it.\u003C\/li\u003E\n\u003Cli\u003E\u003Ci\u003Ek \u003C\/i\u003Eencodes the previous hidden states, representing the other words that receive attention from the query word and might contribute a better representation for it in its current context.\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003Cp\u003EFigure 3 displays how this dot product is computed based on single neuron activations in \u003Ci\u003Eq\u003C\/i\u003E and \u003Ci\u003Ek \u003C\/i\u003Eusing an \u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/arxiv.org\/abs\/1906.05714\u0022\u003Eattention visualization tool called \u003Cspan class=\u0022code\u0022\u003Ebertviz\u003C\/span\u003E\u003C\/a\u003E. Columns in Figure 3 trace the computation of attention scores from the highlighted word on the left, \u201cAmerica,\u201d to the complete sequence of words on the right. For example, to decide to predict \u201c#\u201d following the word \u201cAmerica,\u201d this part of the model focuses its attention on preceding words like \u201cban,\u201d \u201cImmigrants,\u201d and \u201cdisgrace,\u201d (note that the model has broken \u201cImmigrants\u201d into \u201cImm\u201d and \u201cigrants\u201d because \u201cImmigrants\u201d is an uncommon word relative to its component word pieces within pre-trained GPT-2\u0027s original training dataset).\u0026nbsp; The element-wise product shows how individual elements in \u003Ci\u003Eq\u003C\/i\u003E and \u003Ci\u003Ek \u003C\/i\u003Econtribute to the dot product, which encodes the relationship between each word and every other context-providing word as the network learns from new text sequences. The dot product is finally normalized by a \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Softmax_function\u0022\u003Esoftmax function\u003C\/a\u003E that outputs attention scores to be fed into the next layer of the neural network.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/dsio\/fig3.png\u0022 alt=\u0022\u0022\u003E\u003Cspan class=\u0022type-XS\u0022\u003E\u003Cbr\u003E\nFigure 3: The attention patterns for the query word highlighted in grey from one of the fine-tuned GPT-2 generations in Figure 2. Individual vertical bars represent neuron activations, horizontal bars represent vectors, and lines represent the strength of attention between words. Blue indicates positive values, red indicates negative values, and color intensity represents the magnitude of these values.\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003ESyntactic relationships between words like \u201cAmerica,\u201d \u201cban,\u201d and \u201cImmigrants\u201c are valuable from an analysis point of view because they can help identify an information operation\u2019s interrelated keywords and phrases. These indicators can be used to pivot between suspect social media accounts based on shared lexical patterns, help identify common narratives, and even to perform more proactive threat hunting. While the above example only scratches the surface of this complex, 355 million parameter model, \u003Ca href=\u0022https:\/\/arxiv.org\/abs\/1906.04341\u0022\u003Equalitatively visualizing attention to understand the information learned by Transformers\u003C\/a\u003E can help provide analysts insights into linguistic patterns being deployed as part of broader information operations activity.\u003C\/p\u003E\n\u003Ch4\u003EDetecting Information Operations Activity by Fine-Tuning GPT-2 for Classification\u003C\/h4\u003E\n\u003Cp\u003EIn order to further support FireEye Threat Analysts\u2019 work in discovering and triaging information operations activity on social media, we next fine-tuned a detection model to perform classification. Just like when we adapted GPT-2 for a new language modeling task in the previous section, we did not need to make any drastic architectural changes or parameter updates to fine-tune the model for the classification task. However, we did need to provide the model with a labeled dataset, so we grouped together social media posts based on whether they were leveraged in information operations (class label \u003Cspan class=\u0022code\u0022\u003ECLS = 1\u003C\/span\u003E) or were benign (\u003Cspan class=\u0022code\u0022\u003ECLS = 0\u003C\/span\u003E).\u003C\/p\u003E\n\u003Cp\u003EBenign, English-language posts were gathered from verified social media accounts, which generally corresponded to public figures and other prominent individuals or organizations whose posts contained diverse, innocuous content. For the purposes of this blog post, information operations-related posts were obtained from the previously mentioned open source IRA datasets. For the classification task, we separated the IRA datasets that were previously combined for LM fine-tuning, and selected posts from only one of them for the group associated with \u003Cspan class=\u0022code\u0022\u003ECLS = 1\u003C\/span\u003E. To perform dataset selection quantitatively, we fine-tuned LMs on each IRA dataset to produce three different LMs while keeping 33% of the posts from each dataset held out as test data. Doing so allowed us to quantify the overlap between the individual IRA datasets based on how well one dataset\u2019s LM was able to predict post content originating from the other datasets.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/dsio\/fig4.png\u0022 alt=\u0022\u0022\u003E\u003Cspan class=\u0022type-XS\u0022\u003E\u003Cbr\u003E\nFigure 4: Confusion matrix representing perplexities of the LMs on their test datasets. The LM corresponding to the GPT-2 row was not fine-tuned; it corresponds to the pretrained GPT-2 model with reported perplexity of 18.3 on its own test set, which was unavailable for evaluation using the LMs. The Reddit dataset was excluded due to the low volume of samples.\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EIn Figure 4, we show the result of computing \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Perplexity\u0022\u003Eperplexity scores\u003C\/a\u003E for each of the three LMs and the original pre-trained GPT-2 model on held out test data from each dataset. Lower scores indicate better perplexity, which captures the probability of the model choosing the correct next word. The lowest scores fell along the main diagonal of the perplexity confusion matrix, meaning that the fine-tuned LMs were best at predicting the next word on test data originating from within their own datasets. The LM fine-tuned on Twitter\u2019s Elections Integrity dataset displayed the lowest perplexity scores when averaged across all held out test datasets, so we selected posts sampled from this dataset to demonstrate classification fine-tuning.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/dsio\/fig5.png\u0022 alt=\u0022\u0022\u003E\u003Cspan class=\u0022type-XS\u0022\u003E\u003Cbr\u003E\nFigure 5: (A) Training loss histories during GPT-2 fine-tuning for the classification (red) and LM (grey, inset) tasks.\u0026nbsp;(B) ROC curve (red) evaluated on the held out fine-tuning test set, contrasted with random guess (grey dotted).\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003ETo fine-tune for the classification task, we once again processed the selected dataset\u2019s posts through the pre-trained GPT-2 model. This time, activations were fed through adjustable weights into \u003Ci\u003Etwo\u003C\/i\u003E linear output layers instead of just the single one used for the language modeling task in the previous section. Here, fine-tuning was formulated as a multi-task objective with classification loss together with an auxiliary LM loss, which helped accelerate convergence during training and improved the generalization of the model. We also prepended posts with a new\u0026nbsp;\u003Cspan class=\u0022code\u0022\u003E[BOS]\u003C\/span\u003E (i.e. Beginning Of Sentence) string and suffixed posts with the previously mentioned \u003Cspan class=\u0022code\u0022\u003E[CLS]\u003C\/span\u003E class label string, so that each post was fed into the model according to:\u003C\/p\u003E\n\u003Cp style=\u0022text-align: center;\u0022\u003E\u003Cspan class=\u0022code\u0022\u003E\u201c[BOS]Kevin Mandia was on @CNBC\u2019s @MadMoneyOnCNBC with @jimcramer discussing targeted disinformation heading into the\u2026 https:\/\/t.co\/l2xKQJsuwk[CLS]\u201d\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EThe \u003Cspan class=\u0022code\u0022\u003E[BOS]\u003C\/span\u003E string played a similar delimiting role to the \u003Cspan class=\u0022code\u0022\u003E\u0026lt;|endoftext|\u0026gt;\u003C\/span\u003E string used previously in LM fine-tuning, and the \u003Cspan class=\u0022code\u0022\u003E[CLS]\u003C\/span\u003E string encoded the hidden state \u2208 {0, 1} that was the label fed to the model\u2019s classification layer. The example social media post above came from the benign dataset, so this sample\u2019s label was set to \u003Cspan class=\u0022code\u0022\u003ECLS = 0\u003C\/span\u003E during fine-tuning. Figure 5A shows the evolution of classification and auxiliary LM losses during fine-tuning, and Figure 5B displays the \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic\u0022\u003EROC curve\u003C\/a\u003E for the fine-tuned classifier on its test set consisting of around 66,000 social media posts. The convergence of the losses to low values, together with a high Area Under the ROC Curve (i.e. AUC), illustrates that transfer learning allowed this model to accurately detect social media posts associated with IRA information operations activity versus benign ones. Taken together, these metrics indicate that the fine-tuned classifier should generalize well to newly ingested social media posts, providing analysts a capability they can use to separate signal from noise.\u003C\/p\u003E\n\u003Ch4\u003EConclusion\u003C\/h4\u003E\n\u003Cp\u003EIn this blog post, we demonstrated how to fine-tune a neural LM on open source datasets containing social media posts previously leveraged in information operations. Transfer learning allowed us to classify these posts with a high AUC score, and FireEye\u2019s Threat Analysts can utilize this detection capability in order to discover and triage similar emergent operations. Additionally, we showed how Transformer models assign scores to different pieces of text via an attention mechanism. This visualization can be used by analysts to tease apart adversary tradecraft based on posts\u2019 linguistic fingerprints and semantic stylings.\u003C\/p\u003E\n\u003Cp\u003ETransfer learning also allowed us to generate credible synthetic text with low perplexity scores. One of the barriers actors face when devising effective information operations is adequately capturing the nuances and context of the cultural climate in which their targets are situated. Our exercise here suggests this costly step could be bypassed using pre-trained LMs, whose generations can be fine-tuned to embody the zeitgeist of social media. GPT-2\u2019s authors and subsequent researchers have warned about potential malicious use cases enabled by this powerful natural language generation technology, and while it was conducted here for a defensive application in a controlled offline setting using readily available open source data, our research reinforces this concern. \u003Ca href=\u0022https:\/\/openai.com\/blog\/gpt-2-1-5b-release\/\u0022\u003EAs trends towards more powerful and readily available language generation models continue\u003C\/a\u003E, it is important to redouble efforts towards detection as demonstrated by Figure 5 and \u003Ca href=\u0022https:\/\/rowanzellers.com\/grover\/\u0022\u003Eother promising approaches such as Grover\u003C\/a\u003E.\u003C\/p\u003E\n\u003Cp\u003EThis research was conducted during a three-month FireEye IGNITE University Program summer internship, and represents a collaboration between the FDS and FireEye Threat Intelligence\u2019s Information Operations Analysis teams. If you are interested in working on multidisciplinary projects at the intersection of cyber security and machine learning, \u003Ca href=\u0022https:\/\/universityrelations.fireeye.com\/Internships\u0022\u003Eplease consider applying to one of our 2020 summer internships\u003C\/a\u003E.\u003C\/p\u003E\n",
        "jcr:lastModified": "Thu Nov 14 2019 17:07:33 GMT+0000",
        "sling:resourceType": "social\/blog\/components\/entrytext"
      }
    },
    "summary": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "text": "\u003Cp\u003EWe illustrate how\u0026nbsp;to better understand and detect social media information operations using neural language models.\u003C\/p\u003E\n",
      "jcr:lastModified": "Wed Nov 13 2019 20:38:18 GMT+0000",
      "sling:resourceType": "social\/blog\/components\/entrytextteaser"
    },
    "image": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "jcr:lastModified": "Thu Nov 14 2019 17:00:10 GMT+0000",
      "imageRotate": "0"
    }
  }
}
