{
  "jcr:primaryType": "cq:Page",
  "jcr:createdBy": "fireeye_global_admin",
  "jcr:created": "Thu Oct 17 2019 15:35:26 GMT+0000",
  "jcr:content": {
    "jcr:primaryType": "cq:PageContent",
    "jcr:mixinTypes": [
      "mix:versionable"
    ],
    "jcr:createdBy": "fireeye_global_admin",
    "jcr:title": "Definitive Dossier of Devilish Debug Details \u2013 Part Deux: A Didactic Deep Dive into Data Driven Deductions",
    "jcr:versionHistory": "81c71c00-89b7-4840-a230-c34419f09fd6",
    "author": "Matt Berninger",
    "cq:template": "\/apps\/fireeye-blog\/templates\/page_blogpost",
    "jcr:language": "en_us",
    "jcr:predecessors": [
      "4b5945d7-4fc6-45c8-b16a-404aade693dc"
    ],
    "jcr:created": "Thu Oct 17 2019 15:35:26 GMT+0000",
    "cq:lastModified": "Thu Oct 17 2019 15:35:12 GMT+0000",
    "jcr:baseVersion": "4b5945d7-4fc6-45c8-b16a-404aade693dc",
    "jcr:isCheckedOut": true,
    "cq:tags": [
      "fireeye-blog-authors:matt-berninger",
      "fireeye-blog-threat-research:threat-research",
      "fireeye-blog-tags:data-science",
      "fireeye-blog-tags:homepage-carousel",
      "fireeye-blog-tags:latest",
      "fireeye-blog-tags:malware",
      "fireeye-blog-tags:pdb",
      "fireeye-blog-tags:machine-learning"
    ],
    "jcr:uuid": "ae37b4c7-9241-4652-a4ab-702723689172",
    "sling:resourceType": "social\/blog\/components\/page",
    "published": "Thu Oct 17 2019 11:30:00 GMT-0400",
    "cq:lastModifiedBy": "adam.greenberg@fireeye.com",
    "par": {
      "jcr:primaryType": "nt:unstructured",
      "sling:resourceType": "foundation\/components\/parsys",
      "entry": {
        "jcr:primaryType": "nt:unstructured",
        "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
        "text": "\u003Cp\u003EIn \u003Ca adhocenable=\u0022false\u0022 href=\u0022\/content\/fireeye-www\/en_US\/blog\/threat-research\/2019\/08\/definitive-dossier-of-devilish-debug-details-part-one-pdb-paths-malware.html\u0022\u003EPart One of this blog series\u003C\/a\u003E, Steve Miller outlined what PDB paths are, how they appear in malware, how we use them to detect malicious files, and how we sometimes use them to make associations about groups and actors.\u003C\/p\u003E\n\u003Cp\u003EAs Steve continued his research into PDB paths, we became interested in applying more general statistical analysis. The PDB path as an artifact poses an intriguing use case for a couple of reasons.\u003C\/p\u003E\n\u003Cp\u003E\u00adFirst, the PDB artifact is not directly tied to the functionality of the binary. As a byproduct of the compilation process, it contains information about the development environment, and by proxy, the malware author themselves. Rarely do we encounter static malware features with such an interesting tie to the human behind the keyboard, rather than the functionality of the file.\u003C\/p\u003E\n\u003Cp\u003ESecond, file paths are an incredibly complex artifact with many different possible encodings. We had personally been dying to find an excuse to spend more time figuring out how to parse and encode paths in a more useful way. This presented an opportunity to dive into this space and test different approaches to representing file paths in various models.\u003C\/p\u003E\n\u003Cp\u003EThe objectives of our project were:\u003C\/p\u003E\n\u003Col\u003E\n\u003Cli\u003EBuild a large data set of PDB paths and apply some statistical methods to find potentially new signature terms and logic.\u003C\/li\u003E\n\u003Cli\u003EInvestigate whether applying machine learning classification approaches to this problem could improve our detection above writing hand-crafted signatures.\u003C\/li\u003E\n\u003Cli\u003EBuild a PDB classifier as a weak signal for binary analysis.\u003C\/li\u003E\n\u003C\/ol\u003E\n\u003Cp\u003ETo start, we began gathering data. Our dataset, pulled from internal and external sources, started with over 200,000 samples. Once we deduplicated by PDB path, we had around 50,000 samples. Next, we needed to consistently label these samples, so we considered various labeling schemes.\u003C\/p\u003E\n\u003Ch4\u003ELabeling Binaries With PDB Paths\u003C\/h4\u003E\n\u003Cp\u003EFor many of the binaries we had internal FireEye labels, and for others we looked up hashes on VirusTotal (VT) to have a look at their detection rates. This covered the majority of our samples. For a relatively small subset we had disagreements between our internal engine and VT results, which merited a slightly more nuanced policy. The disagreement was most often that our internal assessment determined a file to be benign, but the VT results showed a nonzero percentage of vendors detecting the file as malicious. In these cases we plotted the \u2018VT ratio\u201d: that is, the percentage of vendors labeling the files as malicious (Figure 1).\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/Picture1.png\u0022 alt=\u0022\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 1: Ratio of vendors calling file bad\/total number of vendors\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EThe vast majority of these samples had VT detection ratios below 0.3, and in those cases we labeled the binaries as benign. For the remainder of samples we tried two strategies \u2013 marking them all as malicious, or removing them from the training set entirely. Our classification performance did not change much between these two policies, so in the end we scrapped the remainder of the samples to reduce label noise.\u003C\/p\u003E\n\u003Ch4\u003EBuilding Features\u003C\/h4\u003E\n\u003Cp\u003ENext, we had to start building features. This is where the fun began. Looking at dozens and dozens of PDB paths, we simply started recording various things that \u2018pop out\u2019 to an analyst. As noted earlier, a file path contains tons of implicit information, beyond simply being a string-based artifact. Some analogies we have found useful is that a file path is more akin to a geographical location in its representation of a location on the file system, or like a sentence in that it reflects a series of dependent items.\u003C\/p\u003E\n\u003Cp\u003ETo further illustrate this point, consider a simple file path such as:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003EC:\\Users\\World\\Desktop\\duck\\Zbw138ht2aeja2.pdb\u003C\/span\u003E (\u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/www.virustotal.com\/gui\/file\/01cf217bd22095d6fb257f775f51577c2f50cfe83508425f366c6fcd682ceffa\/detection\u0022\u003Esource file\u003C\/a\u003E)\u003C\/p\u003E\n\u003Cp\u003EThis path tells us several things:\u003C\/p\u003E\n\u003Cul\u003E\n\u003Cli\u003EThis software was compiled on the system drive of the computer\u003C\/li\u003E\n\u003Cli\u003EIn a user profile, under user \u2018World\u2019\u003C\/li\u003E\n\u003Cli\u003EThe project is managed on the Desktop, in a folder called \u2018duck\u2019\u003C\/li\u003E\n\u003Cli\u003EThe filename has a high degree of entropy and is not very easy to remember\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003Cp\u003EIn contrast, consider something such as:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003ED:\\VSCORE5\\BUILD\\VSCore\\release\\EntVUtil.pdb\u003C\/span\u003E (\u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/www.virustotal.com\/gui\/file\/6ea4920e9380a2b3ed202e6a0b02907298c6be925b035f90289d401a36dd82ea\/details\u0022\u003Esource file\u003C\/a\u003E)\u003C\/p\u003E\n\u003Cp\u003EThis indicates:\u003C\/p\u003E\n\u003Cul\u003E\n\u003Cli\u003ECompilation on an external or secondary drive\u003C\/li\u003E\n\u003Cli\u003EWithin a non-user directory\u003C\/li\u003E\n\u003Cli\u003EContains development terms such as \u2018BUILD\u2019 and \u2018release\u2019\u003C\/li\u003E\n\u003Cli\u003EWith a sensible, semi-memorable file name\u003C\/li\u003E\n\u003C\/ul\u003E\n\u003Cp\u003EThese differences seem relatively straightforward and make intuitive sense as to why one might be representative of malware development whereas the other represents a more \u201clegitimate-looking\u201d development environment.\u003C\/p\u003E\n\u003Ch4\u003EFeature Representations\u003C\/h4\u003E\n\u003Cp\u003EHow do we represent these differences to a model? The easiest and most obvious option is to calculate some statistics on each path. Features such as folder depth, path length, entropy, and counting things such as numbers, letters, and special characters in the PDB filename are easy to compute.\u003C\/p\u003E\n\u003Cp\u003EHowever, upon evaluation against our dataset, these features did not help to separate the classes very well. The following are some graphics detailing the distributions of these features between our classes of malicious and benign samples:\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/fourpictures.png\u0022 alt=\u0022\u0022\u003E\u003C\/p\u003E\n\u003Cp\u003EWhile there is potentially \u003Ci\u003Esome\u003C\/i\u003E separation between benign and malicious distributions, these features alone would likely not lead to an effective classifier (we tried). Additionally, we couldn\u2019t easily translate these differences into explicit detection rules. There was more information in the paths that we needed to extract, so we began to look at how to encode the directory names themselves.\u003C\/p\u003E\n\u003Ch4\u003ENormalization\u003C\/h4\u003E\n\u003Cp\u003EAs with any dataset, we had to undertake some steps to normalize the paths. For example, the occurrence of individual usernames, while perhaps interesting from an intelligence perspective, would be represented as distinct entities when in fact they have the same semantic \u003Ci\u003Emeaning. \u003C\/i\u003EThus, we had to detect and replace usernames with \u0026lt;username\u0026gt; to normalize this representation. Other folder idiosyncrasies such as version numbers or randomly generated directories could similarly be normalized into \u0026lt;version\u0026gt; or \u0026lt;random\u0026gt;.\u003C\/p\u003E\n\u003Cp\u003EA typical normalized path might therefore go from this:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003EC:\\Users\\jsmith\\Documents\\Visual Studio 2013\\Projects\\mkzyu91952\\mkzyu91952\\obj\\x86\\Debug\\mkzyu91952.pdb\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003ETo this:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003Ec:\\users\\\u0026lt;username\u0026gt;\\documents\\visual studio 2013\\projects\\\u0026lt;random\u0026gt;\\\u0026lt;random\u0026gt;\\obj\\x86\\debug\\mkzyu91952.pdb\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EYou may notice that the PDB filename itself was not normalized. In this case we wanted to derive features from the filename itself, so we left it. Other approaches could be to normalize it, or even to make note that the same filename string \u2018mkzyu91952\u2019 appears earlier in the path. There are endless possible features when dealing with file paths.\u003C\/p\u003E\n\u003Ch4\u003EDirectory Analysis\u003C\/h4\u003E\n\u003Cp\u003EOnce we had normalized directories, we could start to \u201ctokenize\u201d each directory term, to start performing some statistical analysis.\u0026nbsp;Our main goal of this analysis was to see if there were any directory terms that highly corresponded to maliciousness, or see if there were any simple combinations, such as pairs or triplets, that exhibited similar behavior.\u003C\/p\u003E\n\u003Cp\u003EWe did not find any single directory name that easily separated the classes. That would be too easy. However, we did find some general correlations with directories such as \u201cDesktop\u201d being somewhat more likely to be malicious, and use of shared drives such as Z: to be more indicative of a benign file. This makes intuitive sense given the more collaborative environment a \u201clegitimate\u201d software development process might require. There are, of course, many exceptions and this is what makes the problem tricky.\u003C\/p\u003E\n\u003Cp\u003EAnother strong signal we found, at least in our dataset, is that when the word \u201cDesktop\u201d was in a non-English language and particularly in a different alphabet, the likelihood of that PDB path being tied to a malicious file was very high (Figure 2). While potentially useful, this can be indicative of geographical bias in our dataset, and further research would need to be done to see if this type of signature would generalize.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/Picture2.png\u0022 alt=\u0022\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 2: Unicode desktop folders from malicious samples\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch4\u003EVarious Tokenizing Schemes\u003C\/h4\u003E\n\u003Cp\u003EIn recording the directories of a file path, there are several ways you can represent the path. Let\u2019s use this path to illustrate these different approaches:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003Ec:\\Leave\\smell\\Long\\ruleThis.pdb\u003C\/span\u003E (\u003Ca adhocenable=\u0022false\u0022 href=\u0022https:\/\/www.virustotal.com\/gui\/file\/3a0b32b3f2c39e723b14f831db1a00ea5643864fefccefd4de2e7a5df87282ce\u0022\u003Efile\u003C\/a\u003E)\u003C\/p\u003E\n\u003Ch5\u003EBag of Words\u003C\/h5\u003E\n\u003Cp\u003EOne very simple way is the \u201c\u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Bag-of-words_model\u0022\u003Ebag-of-words\u003C\/a\u003E\u201d approach, which simply treats the path as the distinct set of directory names it contains. Therefore, the aforementioned path would be represented as:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003E[\u2018c:\u2019,\u2019leave\u2019,\u2019smell\u2019,\u2019long\u2019,\u2019rulethis\u2019]\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch5\u003EPositional Analysis\u003C\/h5\u003E\n\u003Cp\u003EAnother approach we considered was recording the position of each directory name, as a distance from the drive. This retained more information about depth, such that a \u2018build\u2019 directory on the desktop would be treated differently than a \u2018build\u2019 directory nine directories further down. For this purpose, we excluded the drives since they would always have the same depth.\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003E[\u2019leave_1\u2019,\u2019smell_2\u2019,\u2019long_3\u2019,\u2019rulethis_4\u2019]\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch5\u003EN-Gram Analysis\u003C\/h5\u003E\n\u003Cp\u003EFinally, we explored breaking paths into n-grams; that is, as a distinct set of n- adjacent directories. For example, a 2-gram representation of this path might look like:\u003C\/p\u003E\n\u003Cp\u003E\u003Cspan class=\u0022code\u0022\u003E[\u2018c:\\leave\u2019,\u2019leave\\smell\u2019,\u2019smell\\long\u2019,\u2019long\\rulethis\u2019]\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EWe tested each of these approaches and while positional analysis and n-grams contained more \u003Ci\u003Einformation\u003C\/i\u003E, in the end, bag-of-words seemed to generalize best. Additionally, using the bag-of-words approach made it easier to extract simple signature logic from the resultant models, as will be shown in a later section.\u003C\/p\u003E\n\u003Ch4\u003ETerm Co-Occurrence\u003C\/h4\u003E\n\u003Cp\u003ESince we had the bag-of-words vectors created for each path, we were also able to evaluate term co-occurrence across benign and malicious files. When we evaluated the co-occurrence of pairs of terms, we found some other interesting pairings that indeed paint two very different pictures of development environments (Figure 3).\u003C\/p\u003E\n\u003Ctable border=\u00221\u0022 cellspacing=\u00220\u0022 cellpadding=\u00220\u0022\u003E\n\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\u003Cb\u003ECorrelated with Malicious Files\u003C\/b\u003E\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\u003Cb\u003ECorrelated with Benign Files\u003C\/b\u003E\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eusers, desktop\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Esrc, retail\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Edocuments, visual studio 2012\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eobj, x64\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Elocal, temporary projects\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Esrc, x86\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eusers, projects\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Esrc, win32\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eusers, documents\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eretail, dynamic\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eappdata, temporary projects\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Esrc, amd64\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022336\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Eusers, x86\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022288\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Esrc, x64\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003C\/tbody\u003E\u003C\/table\u003E\n\u003Cp\u003E\u003Cspan class=\u0022type-XS\u0022\u003EFigure 3: Correlated pairs with malicious and benign files\u003C\/span\u003E\u003C\/p\u003E\n\u003Ch4\u003EKeyword Lists\u003C\/h4\u003E\n\u003Cp\u003EOur bag-of-words representation of the PDB paths then gave us a distinct set of nearly 70,000 distinct terms. The vast majority of these terms occurred once or twice in the entire dataset, resulting in what is known as a \u2018long-tailed\u2019 distribution. Figure 4 is a graph of only the top 100 most common terms in descending order.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/Picture4.png\u0022 alt=\u0022\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 4: Long tailed distribution of term occurrence\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EAs you can see, the counts drop off quickly, and you are left dealing with an enormous amount of terms that may only appear a handful of times. One very simple way to solve this problem, without losing a ton of information, is to simply cut off a keyword list after a certain number of entries. For example, take the top 50 occurring folder names (across both good and bad files), and save them as a keyword list. Then match this list against every path in the dataset. To create features, \u003Ca href=\u0022https:\/\/machinelearningmastery.com\/why-one-hot-encode-data-in-machine-learning\/\u0022\u003Eone-hot encode\u003C\/a\u003E each match. \u0026nbsp;\u003C\/p\u003E\n\u003Cp\u003ERather than arbitrarily setting a cutoff, we wanted to know a bit more about the distribution and understand where might be a good place to set a limit \u2013 such that we would cover enough of the samples without drastically increasing the number of features for our model. We therefore calculated the cumulative number of samples covered by each term, as we iterated down the list from most common to least common. Figure 5 is a graph showing the result.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/Picture5.png\u0022 alt=\u0022\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 5: Cumulative share of samples covered by distinct terms\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EAs you can see, with only a small fraction of the terms, we can arrive at a significant percentage of the cumulative total PDB paths. Setting a simple cutoff at about 70% of the dataset resulted in roughly 230 terms for our total vocabulary. This gave us enough information about the dataset without blowing up our model with too many features (and therefore, dimensions). One-hot encoding the presence of these terms was then the final step in featurizing the directory names present in the paths.\u003C\/p\u003E\n\u003Ch4\u003EYARA Signatures \u003Ci\u003EDo\u003C\/i\u003E Grow on Trees\u003C\/h4\u003E\n\u003Cp\u003EArmed with some statistical features, as well as one-hot encoded keyword matches, we began to train some models on our now-featurized dataset. In doing so, we hoped to use the model training and evaluation process to give us insights into how to build better signatures. If we developed an effective classification model, that would be an added benefit.\u003C\/p\u003E\n\u003Cp\u003EWe felt that tree-based models made sense for this use case for two reasons. First, tree-based models have worked well in the past in domains requiring a certain amount of interpretability and using a blend of quantitative and categorical features. Second, the features we used are largely things we could represent in a YARA signature. Therefore, if our models built boolean logic branches that separated large numbers of PDB files, we could potentially translate these into signatures. This is not to say that other model families could not be used to build strong classifiers. Many other options ranging from \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Logistic_regression\u0022\u003ELogistic Regression\u003C\/a\u003E to \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Deep_learning\u0022\u003EDeep Learning\u003C\/a\u003E could be considered.\u003C\/p\u003E\n\u003Cp\u003EWe fed our featurized training set into a \u003Ca href=\u0022https:\/\/towardsdatascience.com\/decision-trees-in-machine-learning-641b9c4e8052\u0022\u003EDecision Tree\u003C\/a\u003E, having set a couple \u2018hyperparameters\u2019 such as max depth and minimum samples per leaf, etc. We were also able to use a sliding scale of these hyperparameters to dynamically create trees and, essentially, see what shook out. Examining a trained decision tree such as the one in Figure 6 allowed us to immediately build new signatures.\u003C\/p\u003E\n\u003Cp\u003E\u003Cimg src=\u0022\/content\/dam\/fireeye-www\/blog\/images\/definitivedossier2\/Picture6.png\u0022 alt=\u0022\u0022\u003E\u003Cbr\u003E\n\u003Cspan class=\u0022type-XS\u0022\u003EFigure 6: Example decision tree and decision paths\u003C\/span\u003E\u003C\/p\u003E\n\u003Cp\u003EWe found several other interesting tidbits within our decision trees. Some terms that resulted in completely or almost-completely malicious subgroups are:\u003C\/p\u003E\n\u003Ctable border=\u00221\u0022 cellspacing=\u00220\u0022 cellpadding=\u00220\u0022\u003E\n\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd width=\u0022266\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\u003Cb\u003EDirectory Term\u003C\/b\u003E\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022340\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\u003Cb\u003EExample Hashes\u003C\/b\u003E\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022266\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\\poe\\\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022340\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Ea6b2aa2b489fb481c3cd9eab2f4f4f5c\u003C\/p\u003E\n\u003Cp\u003E92904dc99938352525492cd5133b9917\u003C\/p\u003E\n\u003Cp\u003E444be936b44cc6bd0cd5d0c88268fa77\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022266\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\\xampp\\\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022340\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E4d093061c172b32bf8bef03ac44515ae\u003C\/p\u003E\n\u003Cp\u003E4e6c2d60873f644ef5e06a17d85ec777\u003C\/p\u003E\n\u003Cp\u003E52d2a08223d0b5cc300f067219021c90\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022266\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\\temporary projects\\\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022340\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003Ea785bd1eb2a8495a93a2f348c9a8ca67\u003C\/p\u003E\n\u003Cp\u003Ec43c79812d49ca0f3b4da5aca3745090\u003C\/p\u003E\n\u003Cp\u003Ee540076f48d7069bacb6d607f2d389d9\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003Ctr\u003E\u003Ctd width=\u0022266\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E\\stub\\\u003C\/p\u003E\n\u003C\/td\u003E\n\u003Ctd width=\u0022340\u0022 valign=\u0022top\u0022\u003E\u003Cp\u003E5ea538dfc64e28ad8c4063573a46800c\u003C\/p\u003E\n\u003Cp\u003Eadf27ce5e67d770321daf90be6f4d895\u003C\/p\u003E\n\u003Cp\u003Ec6e23da146a6fa2956c3dd7a9314fc97\u003C\/p\u003E\n\u003C\/td\u003E\n\u003C\/tr\u003E\u003C\/tbody\u003E\u003C\/table\u003E\n\u003Cp\u003EWe also found the term \u2018WindowsApplication1\u2019 to be quite useful. 89% of the files in our dataset containing this directory were malicious. Cursory research indicates that this is the default directory generated when using Visual Studio to compile a Windows binary. Once again, this makes some intuitive sense for finding malware authors. Training and evaluating decision trees with various parameters turned out to be a hugely productive exercise in discovering potential new signature terms and logic.\u003C\/p\u003E\n\u003Ch4\u003EClassification Accuracy and Findings\u003C\/h4\u003E\n\u003Cp\u003ESince we now had a large dataset of PDB paths and features, we wanted to see if we could train a traditional classifier to separate good files from bad. Using a \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Random_forest\u0022\u003ERandom Forest\u003C\/a\u003E with some tuning, we were able to achieve an average accuracy of 87% over 10 cross validations. However, while our recall (the percentage of bad things we could identify with the model) was relatively high at 89%, our malware precision (the share of those things we called bad that were actually bad) was far too low, hovering at or below 50%. This indicates that using this model alone for malware detection would result in an unacceptably large number of false positives, were we to deploy it in the wild as a singular detection platform. However, used in conjunction with other tools, this could be a useful weak signal to assist with analysis.\u003C\/p\u003E\n\u003Ch4\u003EConclusion and Next Steps\u003C\/h4\u003E\n\u003Cp\u003EWhile our journey of statistical PDB analysis did not yield a magic malware classifier, it did yield a number of useful findings that we were hoping for:\u003C\/p\u003E\n\u003Col\u003E\n\u003Cli\u003EWe developed several file path feature functions which are transferable to other models under development.\u003C\/li\u003E\n\u003Cli\u003EBy diving into statistical analysis of the dataset, we were able to identify new keywords and logic branches to include in YARA signatures. These signatures have since been deployed and discovered new malware samples.\u003C\/li\u003E\n\u003Cli\u003EWe answered a number of our own general research questions about PDB paths, and were able to dispel some theories we had not fully tested with data.\u003C\/li\u003E\n\u003C\/ol\u003E\n\u003Cp\u003EWhile building an independent classifier was not the primary goal, improvements can surely be made to improve the end model accuracy. Generating an even larger, more diverse dataset would likely make the biggest impact on our accuracy, recall, and precision. Further hyperparameter tuning and feature engineering could also help. There is a large amount of established research into text classification using various deep learning methods such as \u003Ca href=\u0022https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory\u0022\u003ELSTMs\u003C\/a\u003E, which could be applied effectively to a larger dataset.\u003C\/p\u003E\n\u003Cp\u003EPDB paths are only one small family of file paths that we encounter in the field of cyber security. Whether in initial infection, staging, or another part of the attack lifecycle, the file paths found during forensic analysis can reveal incredibly useful information about adversary activity. We look forward to further community research on how to properly extract and represent that information.\u003C\/p\u003E\n",
        "jcr:lastModified": "Thu Oct 17 2019 15:34:41 GMT+0000",
        "sling:resourceType": "social\/blog\/components\/entrytext"
      }
    },
    "summary": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "text": "\u003Cp\u003EOur journey of statistical PDB analysis did not yield a magic malware classifier, but did yield a number of useful findings.\u003C\/p\u003E\n",
      "jcr:lastModified": "Wed Oct 16 2019 21:33:55 GMT+0000",
      "sling:resourceType": "social\/blog\/components\/entrytextteaser"
    },
    "image": {
      "jcr:primaryType": "nt:unstructured",
      "jcr:lastModifiedBy": "adam.greenberg@fireeye.com",
      "jcr:lastModified": "Thu Oct 17 2019 15:35:12 GMT+0000",
      "imageRotate": "0"
    }
  }
}
